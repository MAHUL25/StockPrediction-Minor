{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotData(data, graph_title, graph_name):\n",
    "    matplotlib.use('Agg')\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    plt.plot(data.index, data)\n",
    "    plt.title(graph_title)\n",
    "    # plt.show()\n",
    "\n",
    "    plt.savefig(f'{graph_name}.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxData(data, col_name):\n",
    "    x = data.describe()\n",
    "    x = x[col_name]\n",
    "    # minVal = np.int32(x.loc['min'])\n",
    "    minVal = x.loc['min']\n",
    "    # minVal = round(minVal, 4)\n",
    "    # maxVal = np.int32(x.loc['max'])\n",
    "    # maxVal = round(maxVal, 4)\n",
    "    maxVal = x.loc['max']\n",
    "\n",
    "    return minVal, maxVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataImport(stock_name):\n",
    "    # t_day = date.today()\n",
    "    # data = yf.download(stock_name, start=f\"{t_day.year - 5}-01-01\", end=f\"{t_day.year}-{t_day.month-1}-01\")\n",
    "    data = yf.download(stock_name)\n",
    "    close_data = data['Close']\n",
    "    # PlotData(close_data, stock_name, \"fullStock\")\n",
    "    open_min, open_max = MinMaxData(data, 'Open')\n",
    "    high_min, high_max = MinMaxData(data, 'High')\n",
    "    low_min, low_max = MinMaxData(data, 'Low')\n",
    "    vol_min, vol_max = MinMaxData(data, 'Volume')\n",
    "    \n",
    "    d = {\"open_min\": open_min, \"open_max\": open_max, \"high_min\": high_min, \"high_max\": high_max, \n",
    "    \"low_min\": low_min, \"low_max\": low_max, \"vol_min\": vol_min, \"vol_max\": vol_max}\n",
    "\n",
    "    return data, d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data, d = DataImport(\"ETH-USD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotData(data['Close'], \"INFY\", \"fullStock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-03-11</th>\n",
       "      <td>0.583984</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.583984</td>\n",
       "      <td>0.732422</td>\n",
       "      <td>0.483835</td>\n",
       "      <td>172512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-03-12</th>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.728516</td>\n",
       "      <td>0.481255</td>\n",
       "      <td>39897600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-03-15</th>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.730469</td>\n",
       "      <td>0.658203</td>\n",
       "      <td>0.662109</td>\n",
       "      <td>0.437387</td>\n",
       "      <td>12672000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-03-16</th>\n",
       "      <td>0.667969</td>\n",
       "      <td>0.691406</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.433516</td>\n",
       "      <td>9984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-03-17</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.699219</td>\n",
       "      <td>0.652344</td>\n",
       "      <td>0.660156</td>\n",
       "      <td>0.436097</td>\n",
       "      <td>15449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-15</th>\n",
       "      <td>17.690001</td>\n",
       "      <td>17.709999</td>\n",
       "      <td>17.260000</td>\n",
       "      <td>17.270000</td>\n",
       "      <td>17.270000</td>\n",
       "      <td>11374300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-16</th>\n",
       "      <td>16.980000</td>\n",
       "      <td>17.190001</td>\n",
       "      <td>16.980000</td>\n",
       "      <td>17.049999</td>\n",
       "      <td>17.049999</td>\n",
       "      <td>13033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-17</th>\n",
       "      <td>17.139999</td>\n",
       "      <td>17.180000</td>\n",
       "      <td>16.870001</td>\n",
       "      <td>16.950001</td>\n",
       "      <td>16.950001</td>\n",
       "      <td>17034100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-18</th>\n",
       "      <td>16.260000</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>16.040001</td>\n",
       "      <td>16.510000</td>\n",
       "      <td>16.510000</td>\n",
       "      <td>31702900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-19</th>\n",
       "      <td>16.760000</td>\n",
       "      <td>16.950001</td>\n",
       "      <td>16.680000</td>\n",
       "      <td>16.809999</td>\n",
       "      <td>16.809999</td>\n",
       "      <td>16181900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6319 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume\n",
       "Date                                                                        \n",
       "1999-03-11   0.583984   0.781250   0.583984   0.732422   0.483835  172512000\n",
       "1999-03-12   0.734375   0.761719   0.671875   0.728516   0.481255   39897600\n",
       "1999-03-15   0.730469   0.730469   0.658203   0.662109   0.437387   12672000\n",
       "1999-03-16   0.667969   0.691406   0.656250   0.656250   0.433516    9984000\n",
       "1999-03-17   0.656250   0.699219   0.652344   0.660156   0.436097   15449600\n",
       "...               ...        ...        ...        ...        ...        ...\n",
       "2024-04-15  17.690001  17.709999  17.260000  17.270000  17.270000   11374300\n",
       "2024-04-16  16.980000  17.190001  16.980000  17.049999  17.049999   13033300\n",
       "2024-04-17  17.139999  17.180000  16.870001  16.950001  16.950001   17034100\n",
       "2024-04-18  16.260000  16.900000  16.040001  16.510000  16.510000   31702900\n",
       "2024-04-19  16.760000  16.950001  16.680000  16.809999  16.809999   16181900\n",
       "\n",
       "[6319 rows x 6 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelBuilding(data):\n",
    "    columns_to_4decimal = ['Open', 'High', 'Low', 'Close']\n",
    "\n",
    "    data[columns_to_4decimal] = np.round(data[columns_to_4decimal],4)\n",
    "    # print(data)\n",
    "    X = data[['Open', 'Low', 'High', 'Volume']]\n",
    "    y = data['Close']\n",
    "\n",
    "    #split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    #creates the svr model\n",
    "    svr_model = SVR(kernel = 'rbf', C=100, epsilon=0.1)\n",
    "\n",
    "\n",
    "    #train the model\n",
    "    svr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    #defines the parameter for grid search \n",
    "    param_grid = {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': [1, 10, 50, 100],\n",
    "        'epsilon': [0.01, .1, 0.2, 0.5]\n",
    "    }\n",
    "    svr = SVR()\n",
    "\n",
    "    grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    normal_pred = grid_search.fit(X_train_normalized, y_train)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "\n",
    "    #trains the model with the best parameter \n",
    "    best_svr_model = SVR(**best_params)\n",
    "    best_svr_model.fit(X_train_normalized, y_train)\n",
    "\n",
    "    return best_svr_model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, scaler = modelBuilding(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Next30_days(data, d):\n",
    "    new_data = pd.DataFrame()\n",
    "    new_data['Date'] = pd.to_datetime(data.index)\n",
    "    new_data = new_data.sort_values(by='Date')\n",
    "\n",
    "    # Extract the last date in the data\n",
    "    last_date = new_data['Date'].max()\n",
    "\n",
    "    # Generate dates for the next 30 days\n",
    "    next_30_days_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "\n",
    "    # Create a DataFrame for the next 30 days data\n",
    "    next_30_days_data = pd.DataFrame({'Date': next_30_days_dates})\n",
    "    \n",
    "    # next_30_days_data['Volume'] = np.random.randint(100000, 500000, size=len(next_30_days_data))\n",
    "    next_30_days_data['Open'] = np.random.randint(d['open_min'], d['open_max'], size=len(next_30_days_data))\n",
    "    next_30_days_data['Low'] = np.random.randint(d['low_min'], d['low_max'], size=len(next_30_days_data))\n",
    "    next_30_days_data['High'] = np.random.randint(d['high_min'], d['high_max'], size=len(next_30_days_data))\n",
    "    next_30_days_data['Volume'] = np.random.randint(d['vol_min'], d['vol_max'], size=len(next_30_days_data))\n",
    "\n",
    "    next_30_days_data.set_index('Date', inplace=True)\n",
    "    # Print or use the prepared next 30 days data\n",
    "    # print(next_30_days_data)\n",
    "\n",
    "    return next_30_days_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictData(data, d):\n",
    "    next_30_days_data = Next30_days(data, d)\n",
    "\n",
    "    next_30_days_scaled = scaler.transform(next_30_days_data)\n",
    "\n",
    "    # Make predictions for the next 30 days\n",
    "    predictions_next_30_days = model.predict(next_30_days_scaled)\n",
    "\n",
    "    return predictions_next_30_days, next_30_days_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, next_data = predictData(data, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CombineData(data, pred, next_data):\n",
    "    original_close_data = pd.DataFrame()\n",
    "    original_close_data['Close'] = data['Close']\n",
    "    df = pd.DataFrame(pred, index=next_data.index)\n",
    "    df.columns = ['Close']\n",
    "    # original_close_data\n",
    "    # df\n",
    "    predicted_30_days_data_combined = pd.concat([original_close_data, df])\n",
    "    \n",
    "    return predicted_30_days_data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final = CombineData(data, pred, next_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPredict(data_final, stock_name):\n",
    "    x = data_final['Close']\n",
    "    x = x[::-100]\n",
    "    PlotData(x, f\"{stock_name} Prediction\", \"Data_Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotPredict(data_final, \"INFY\")\n",
    "# PlotData(x, f\"INFY Prediction\", \"Data_Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneYear_data(data):\n",
    "    data = data['Close']\n",
    "    one_year_data = data.tail(365)\n",
    "    # PlotData(one_year_data, \"Yearly Stock Data\", \"yearly\")\n",
    "    return one_year_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_year_data = OneYear_data(data)\n",
    "# PlotData(one_year_data, \"Yearly Stock Data\", \"yearly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LastMonth_data(data):\n",
    "    data = data['Close']\n",
    "    last_month_data = data.tail(30)\n",
    "    # PlotData(last_moth_data, \"Monthly Stock Data\", \"monthly\")\n",
    "    return last_month_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_month_data = LastMonth_data(data)\n",
    "# PlotData(last_month_data, \"Monthly Stock Data\", \"monthly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LastWeek_data(data):\n",
    "    data = data['Close']\n",
    "    last_week_data = data.tail(7)\n",
    "    # PlotData(last_week_data, \"Weekly Stock Data\", \"weekly\")\n",
    "\n",
    "    return last_week_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_week_data = LastWeek_data(data)\n",
    "# PlotData(last_week_data, \"Weekly Stock Data\", \"weekly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = {\n",
    "    \"model\": model,\n",
    "    \"scaler\": scaler,\n",
    "    \"x_data\": x,\n",
    "    \"one_year_data\": one_year_data,\n",
    "    \"last_month_data\": last_month_data,\n",
    "    \"last_weed_data\": last_week_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./stockpred/Model/svm_model.pkl', 'wb') as file:\n",
    "    pickle.dump(full_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./stockpred/Model/svm_model.pkl', 'rb') as file:\n",
    "    load_data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "data, d = load_data['dataImport'](\"INFY\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
